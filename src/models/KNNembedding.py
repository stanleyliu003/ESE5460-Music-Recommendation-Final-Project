# -*- coding: utf-8 -*-
"""OpenL3Embedding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sQ34Kg_Mms1vJ8MLmGn7AKqEC_dswvFw
"""

!apt-get -qq install -y ffmpeg

!pip install openl3 faiss-cpu torchopenl3 soundfile librosa tqdm

from google.colab import drive
drive.mount('/content/drive')

import os

# Define the base project path
project_path = '/content/drive/MyDrive/ESE 5460/Project'


os.makedirs(project_path, exist_ok=True)

os.chdir(project_path)

print(f"Current working directory set to: {os.getcwd()}")

import glob
import numpy as np
import pandas as pd
from tqdm import tqdm

import torch
import torchaudio
import torchopenl3
import faiss

# Paths
GTZAN_ROOT = "data/gtzan_raw"      # REAL songs
AI_DIR = "data/sonics_raw"     # FAKE songs / query points

assert os.path.isdir(GTZAN_ROOT), f"Missing: {GTZAN_ROOT}"
assert os.path.isdir(AI_DIR), f"Missing: {AI_DIR}"

device = "cuda" if torch.cuda.is_available() else "cpu"
print("device:", device)

TARGET_SR = 16000  # downsample everything to 16k
DURATION  = 30.0   # seconds
SAMPLES   = int(TARGET_SR * DURATION)

# TorchOpenL3 config
CONTENT_TYPE = "music"
INPUT_REPR   = "mel128"
EMBED_SIZE   = 512
HOP_SIZE     = 0.1 # number of seconds to jump
CENTER       = True
BATCH_SIZE   = 32

# Pooling -> one vector per track
POOLING      = "mean"   # "mean" or "max"
L2_NORMALIZE = True

def list_audio_files(root: str, exts=(".wav", ".mp3", ".flac", ".m4a", ".ogg", ".aiff", ".aac")):
    files = glob.glob(os.path.join(root, "**", "*"), recursive=True)
    files = [f for f in files if os.path.isfile(f) and os.path.splitext(f)[1].lower() in exts]
    files.sort()
    return files

def infer_label_from_path(path: str) -> str:
    # Works with GTZAN layout: .../genres_original/<genre>/<file>.wav
    parts = os.path.normpath(path).split(os.sep)
    if "genres_original" in parts:
        i = parts.index("genres_original")
        if i + 1 < len(parts):
            return parts[i + 1]
    return os.path.basename(os.path.dirname(path))

def load_audio_fixed(path: str, target_sr: int, n_samples: int):
    """
    Load -> mono -> resample -> trim/pad to fixed length
    Returns: (audio_np_float32, sr)
    """
    wav, sr = torchaudio.load(path)          # (C, T)
    wav = wav.mean(dim=0, keepdim=True)      # mono (1, T)

    if sr != target_sr:
        wav = torchaudio.functional.resample(wav, sr, target_sr)

    wav = wav.squeeze(0)  # (T,)

    if wav.numel() > n_samples:
        wav = wav[:n_samples]
    elif wav.numel() < n_samples:
        wav = torch.nn.functional.pad(wav, (0, n_samples - wav.numel()))
    return wav.cpu().numpy().astype(np.float32), target_sr

def pool_embedding(emb_TxD: np.ndarray) -> np.ndarray:
    """
    Convert frame-level OpenL3 embeddings (T, D) -> song-level vector (D,)
    """
    if POOLING == "mean":
        v = emb_TxD.mean(axis=0)
    elif POOLING == "max":
        v = emb_TxD.max(axis=0)
    else:
        raise ValueError("POOLING must be 'mean' or 'max'")

    if L2_NORMALIZE:
        v = v / (np.linalg.norm(v) + 1e-12)

    return v.astype(np.float32)

tmodel = torchopenl3.models.load_audio_embedding_model(
    input_repr=INPUT_REPR,
    content_type=CONTENT_TYPE,
    embedding_size=EMBED_SIZE
).to(device).eval()

print("TorchOpenL3 model loaded.")

# HAVEN'T WIRED THIS IN YET BUT I CACHED EMBEDDINGS AT END
def load_gtzan_embeddings(
    cache_dir: str = "embeddings_cache",
    pooled: bool = True,
    build_faiss: bool = True,
):
    meta_path = os.path.join(cache_dir, "gtzan_real_meta.csv")
    assert os.path.exists(meta_path), f"Missing {meta_path}"

    meta = pd.read_csv(meta_path)

    if pooled:
        X_path = os.path.join(cache_dir, "gtzan_real_X_pooled.npy")
        assert os.path.exists(X_path), f"Missing {X_path}"
        X = np.load(X_path)

        if X.ndim != 2:
            raise ValueError(f"Pooled embeddings must be (N, D), got {X.shape}")

        # Ensure float32 + contiguous for FAISS
        X = np.ascontiguousarray(X, dtype=np.float32)

    else:
        X_path = os.path.join(cache_dir, "gtzan_real_X.npy")
        assert os.path.exists(X_path), f"Missing {X_path}"
        X = np.load(X_path)

        if X.ndim != 3:
            raise ValueError(f"Frame-level embeddings must be (N, T, D), got {X.shape}")

    index = None
    if build_faiss:
        if not pooled:
            raise ValueError("FAISS index requires pooled=True embeddings")

        d = X.shape[1]
        index = faiss.IndexFlatIP(d)
        index.add(X)

    print("Loaded embeddings:")
    print("  X shape:", X.shape)
    print("  meta rows:", len(meta))
    if index is not None:
        print("  FAISS index size:", index.ntotal)

    return X, meta, index

# Embed audio file given by path into an OpenL3 embedding
@torch.no_grad()
def embed_path(path: str) -> np.ndarray:
    audio, sr = load_audio_fixed(path, TARGET_SR, SAMPLES)

    emb, ts = torchopenl3.get_audio_embedding(
        audio=audio,
        sr=sr,
        model=tmodel,
        hop_size=HOP_SIZE,
        center=CENTER,
        batch_size=BATCH_SIZE,
        verbose=0
    )

    if isinstance(emb, torch.Tensor):
        emb = emb.detach().cpu().numpy()
    else:
        emb = np.asarray(emb)

    if emb.ndim == 3 and emb.shape[0] == 1:
        emb = emb[0]  # (T, D)

    if emb.ndim != 2:
        raise ValueError(f"Expected (T, D) or (1, T, D), got {emb.shape}")

    v = emb.mean(axis=0)  # (D,)
    v /= np.linalg.norm(v) + 1e-12
    return v.astype(np.float32)

# Embed every file in folder [.wav files in this case]
def embed_folder_to_matrix(root: str, add_label: bool = False, desc: str = "Embedding"):
    files = list_audio_files(root)
    if not files:
        raise FileNotFoundError(f"No .wav files found under {root}")

    rows = []
    vecs = []
    skipped = 0

    for p in tqdm(files, desc=desc):
        try:
            v = embed_path(p)
        except Exception as e:
            skipped += 1
            print(f"[SKIP] {p} ({type(e).__name__}: {e})")
            continue

        row = {"path": p}
        if add_label:
            row["label"] = infer_label_from_path(p)
        rows.append(row)
        vecs.append(v)

    if not vecs:
        raise RuntimeError(f"No embeddings produced from {root} (all files failed).")

    dims = sorted(set(v.shape[0] for v in vecs))
    print("Unique dims:", dims, "| embedded:", len(vecs), "| skipped:", skipped)
    if len(dims) != 1:
        raise ValueError(f"Inconsistent embedding dimensions: {dims}")

    X = np.stack(vecs, axis=0).astype(np.float32)
    meta = pd.DataFrame(rows)
    return X, meta

# # Real songs: GTZAN
# X_real, meta_real = embed_folder_to_matrix(
#     GTZAN_ROOT,
#     add_label=True,
#     desc="Embedding GTZAN (REAL)"
# )

# print("X_real:", X_real.shape)
# display(meta_real.head())

"""#-------------------------LOAD EMBEDDINGS-------------------------"""

# HAVEN'T WIRED THIS IN YET BUT I CACHED EMBEDDINGS AT END
def load_gtzan_embeddings(
    cache_dir: str = "embeddings_cache",
    pooled: bool = True,
    build_faiss: bool = True,
):
    meta_path = os.path.join(cache_dir, "gtzan_real_meta.csv")
    assert os.path.exists(meta_path), f"Missing {meta_path}"

    meta = pd.read_csv(meta_path)

    if pooled:
        X_path = os.path.join(cache_dir, "gtzan_real_X_pooled.npy")
        assert os.path.exists(X_path), f"Missing {X_path}"
        X = np.load(X_path)

        if X.ndim != 2:
            raise ValueError(f"Pooled embeddings must be (N, D), got {X.shape}")

        # Ensure float32 + contiguous for FAISS
        X = np.ascontiguousarray(X, dtype=np.float32)

    else:
        X_path = os.path.join(cache_dir, "gtzan_real_X.npy")
        assert os.path.exists(X_path), f"Missing {X_path}"
        X = np.load(X_path)

        if X.ndim != 3:
            raise ValueError(f"Frame-level embeddings must be (N, T, D), got {X.shape}")

    print("Loaded embeddings:")
    print("  X shape:", X.shape)
    print("  meta rows:", len(meta))

    return X, meta

X_real_song, meta_real = load_gtzan_embeddings(pooled=True)

"""## KNN with FAISS"""

print(X_real_song.shape)  # (999, 512)

# # Pool time dimension
# X_real_song = X_real.mean(axis=1).astype(np.float32)

# # L2 normalize (important for cosine similarity)
# X_real_song /= np.linalg.norm(X_real_song, axis=1, keepdims=True) + 1e-12

# print(X_real_song.shape)  # (999, 512)

d = X_real_song.shape[1]

# Since we L2-normalized, inner product == cosine similarity
index = faiss.IndexFlatIP(d)
index.add(X_real_song)

print("FAISS index built. Total vectors:", index.ntotal)

def knn_query_vector(q_vec: np.ndarray, k: int = 10):
    q = q_vec.astype(np.float32)[None, :]  # (1, D)
    scores, idxs = index.search(q, k)
    out = meta_real.iloc[idxs[0]].copy()
    out["score"] = scores[0]
    return out

def knn_query_path(query_path: str, k: int = 10):
    q_vec = embed_path(query_path)
    return knn_query_vector(q_vec, k=k)

ai_files = list_audio_files(AI_DIR)

metadata_path = os.path.join(project_path, "data/sonics_raw/metadata/fake_songs.csv")

# Read the metadata CSV
try:
    ai_metadata_df = pd.read_csv(metadata_path)
except FileNotFoundError:
    print(f"Error: Metadata file not found at {metadata_path}")
    ai_metadata_df = pd.DataFrame()

genre_mapping = {}
if not ai_metadata_df.empty:
    for _, row in ai_metadata_df.iterrows():
        filename_base = row['filename']
        genre_mapping[filename_base] = row['genre']

# Map ai_files path with its corresponding "genre" field
ai_files_with_genres = []
for full_path in ai_files:
    filename_with_ext = os.path.basename(full_path)
    filename_base, _ = os.path.splitext(filename_with_ext)
    genre = genre_mapping.get(filename_base, "unknown")
    ai_files_with_genres.append((full_path, genre))

print("SONICS wav count:", len(ai_files))
print("Example SONICS file:", ai_files[1] if len(ai_files) > 1 else "None")

if not ai_metadata_df.empty:
    print("\nAll unique genres from metadata_path:")
    print(ai_metadata_df['genre'].unique())
else:
    print("Metadata DataFrame is empty, cannot extract genres.")

import numpy as np
import os
from tqdm import tqdm

# Caching mechanism for map_ai_genre_to_closest_real
_ai_genre_to_real_map_cache = {}

def map_ai_genre_to_closest_real(
    ai_genre_to_map: str,
    target_real_genres: list,
    gtzan_genre_centroids: dict,
    ai_files_with_genres: list
) -> str:
    # IMMEDIATE CHECK: If the AI genre is already in the target list, return it.
    if ai_genre_to_map in target_real_genres:
        print(f"AI genre '{ai_genre_to_map}' is already a target real genre. No mapping needed.")
        return ai_genre_to_map

    # Use caching to prevent re-computation
    cache_key = (ai_genre_to_map, tuple(sorted(target_real_genres)))
    if cache_key in _ai_genre_to_real_map_cache:
        print(f"Using cached result for AI genre '{ai_genre_to_map}'")
        return _ai_genre_to_real_map_cache[cache_key]

    print(f"Mapping AI genre '{ai_genre_to_map}' to closest real genre from {target_real_genres}...")

    # Calculate centroid
    ai_songs_for_this_genre = [path for path, genre in ai_files_with_genres if genre == ai_genre_to_map]

    if not ai_songs_for_this_genre:
        result = f"No AI songs found for genre '{ai_genre_to_map}' to form a centroid."
        _ai_genre_to_real_map_cache[cache_key] = result
        return result

    ai_song_embeddings = []
    print(f"Embedding {len(ai_songs_for_this_genre)} songs for AI genre '{ai_genre_to_map}'...")

    for ai_song_path in tqdm(ai_songs_for_this_genre, desc=f"Embedding AI songs for '{ai_genre_to_map}'"):
        try:
            emb = embed_path(ai_song_path)
            ai_song_embeddings.append(emb)
        except Exception as e:
            print(f"[ERROR] Skipping AI song {os.path.basename(ai_song_path)} for centroid calculation: {e}")
            continue

    if not ai_song_embeddings:
        result = f"Failed to embed any songs for AI genre '{ai_genre_to_map}'. Cannot form centroid."
        _ai_genre_to_real_map_cache[cache_key] = result
        return result

    ai_genre_centroid = np.mean(ai_song_embeddings, axis=0)
    ai_genre_centroid = ai_genre_centroid / (np.linalg.norm(ai_genre_centroid) + 1e-12) # L2 normalize

    filtered_gtzan_centroids = {}
    for genre in target_real_genres:
        if genre in gtzan_genre_centroids:
            filtered_gtzan_centroids[genre] = gtzan_genre_centroids[genre]
        else:
            print(f"Warning: Real genre '{genre}' not found in GTZAN centroids. Skipping.")

    if not filtered_gtzan_centroids:
        result = f"None of the target real genres {target_real_genres} found in GTZAN centroids."
        _ai_genre_to_real_map_cache[cache_key] = result
        return result

    max_similarity = -1
    closest_real_genre = "No match found"

    for real_genre, real_centroid in filtered_gtzan_centroids.items():
        similarity = np.dot(ai_genre_centroid, real_centroid)
        if similarity > max_similarity:
            max_similarity = similarity
            closest_real_genre = real_genre

    result = closest_real_genre
    _ai_genre_to_real_map_cache[cache_key] = result
    print(f"AI genre '{ai_genre_to_map}' is most similar to real genre: '{closest_real_genre}' (Similarity: {max_similarity:.4f})")
    return result

print("Pre-computing GTZAN genre centroids...")
gtzan_genre_centroids = {}

if 'meta_real' in locals() and 'X_real_song' in locals():
    for genre_label in meta_real['label'].unique():
        genre_indices = meta_real[meta_real['label'] == genre_label].index
        valid_indices = [i for i in genre_indices if i < len(X_real_song)]

        if valid_indices:
            genre_embeddings = X_real_song[valid_indices]
            centroid = np.mean(genre_embeddings, axis=0)
            centroid = centroid / (np.linalg.norm(centroid) + 1e-12) # L2 normalize
            gtzan_genre_centroids[genre_label] = centroid
        else:
            print(f"Warning: No valid embeddings found for GTZAN genre '{genre_label}'.")
    print("GTZAN genre centroids pre-computed.")
else:
    print("Skipped pre-computation: 'meta_real' or 'X_real_song' not defined in this scope.")

target_real_genres = ["metal", "disco", "classical", "blues", "hiphop", "jazz", "country", "rock", "pop", "reggae"]

"""# Task
Identify the first AI song and its genre from the `ai_files_with_genres` list. Then, map this AI genre to its closest real GTZAN genre using the `map_ai_genre_to_closest_real` function with the pre-computed `gtzan_genre_centroids`. After obtaining the mapped real genre, perform a k-nearest neighbors query (`k=100`) for the first AI song using `knn_query_path`. Finally, filter these 100 results to include only those songs belonging to the mapped real genre, and display the top 10 such songs sorted by cosine similarity in descending order.
"""

if ai_files_with_genres:
    first_ai_file_path, first_ai_genre = ai_files_with_genres[0]
    print(f"First AI file path: {first_ai_file_path}")
    print(f"First AI genre: {first_ai_genre}")
else:
    print("The ai_files_with_genres list is empty.")

mapped_real_genre = map_ai_genre_to_closest_real(
    ai_genre_to_map=first_ai_genre,
    target_real_genres=target_real_genres,
    gtzan_genre_centroids=gtzan_genre_centroids,
    ai_files_with_genres=ai_files_with_genres
)

print(f"The AI genre '{first_ai_genre}' is mapped to the real genre: '{mapped_real_genre}'.")

print(f"Performing KNN query for AI song: {first_ai_file_path} (AI genre: {first_ai_genre}) and filtering for mapped real genre: {mapped_real_genre}")

k = 100
knn_results = knn_query_path(first_ai_file_path, k=k)

filtered_knn_results = knn_results[knn_results['label'] == mapped_real_genre]

top_10_filtered_results = filtered_knn_results.sort_values(by='score', ascending=False).head(10)

print(f"\nTop 10 KNN results for AI song '{os.path.basename(first_ai_file_path)}' matching real genre '{mapped_real_genre}':")
display(top_10_filtered_results)

# # Run one query (top-10 similar REAL GTZAN songs)
# if ai_files:
#     print("\nKNN query for the first AI file:")
#     display(knn_query_path(ai_files[0], k=10))

if ai_files_with_genres:
    first_ai_file_path, first_ai_genre = ai_files_with_genres[0]
    print(f"First AI file path: {first_ai_file_path}")
    print(f"First AI genre: {first_ai_genre}")
else:
    print("The ai_files_with_genres list is empty.")

mapped_real_genre = map_ai_genre_to_closest_real(
    ai_genre_to_map=first_ai_genre,
    target_real_genres=target_real_genres,
    gtzan_genre_centroids=gtzan_genre_centroids,
    ai_files_with_genres=ai_files_with_genres
)

print(f"The AI genre '{first_ai_genre}' is mapped to the real genre: '{mapped_real_genre}'.")

print(f"Performing KNN query for AI song: {first_ai_file_path} (AI genre: {first_ai_genre}) and filtering for mapped real genre: {mapped_real_genre}")

k = 100
knn_results = knn_query_path(first_ai_file_path, k=k)

filtered_knn_results = knn_results[knn_results['label'] == mapped_real_genre]

top_10_filtered_results = filtered_knn_results.sort_values(by='score', ascending=False).head(10)

print(f"\nTop 10 KNN results for AI song '{os.path.basename(first_ai_file_path)}' matching real genre '{mapped_real_genre}':")
display(top_10_filtered_results)

os.makedirs("embeddings_cache", exist_ok=True)

# np.save("embeddings_cache/gtzan_real_X.npy", X_real)
# np.save("embeddings_cache/gtzan_real_X_pooled.npy", X_real_song)
meta_real.to_csv("embeddings_cache/gtzan_real_meta.csv", index=False)

print("Saved real embeddings to embeddings_cache/")

"""#Run 50 files"""

import random
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os

# 1. Take 50 random samples (or fewer if list is smaller)
sample_size = 50
num_samples = min(sample_size, len(ai_files_with_genres))
random_samples = random.sample(ai_files_with_genres, num_samples)

results_data = []

print(f"Processing {num_samples} random samples...")

for i, (file_path, ai_genre) in enumerate(random_samples):
    # Map AI genre to Real genre
    mapped_real_genre = map_ai_genre_to_closest_real(
        ai_genre_to_map=ai_genre,
        target_real_genres=target_real_genres,
        gtzan_genre_centroids=gtzan_genre_centroids,
        ai_files_with_genres=ai_files_with_genres
    )

    # Perform KNN Query
    knn_results = knn_query_path(file_path, k=100)

    filtered_results = knn_results[knn_results['label'] == mapped_real_genre]

    top_10 = filtered_results.sort_values(by='score', ascending=False).head(10)

    if not top_10.empty:
        avg_similarity = top_10['score'].mean()

        results_data.append({
            'File': os.path.basename(file_path),
            'AI Genre': ai_genre,
            'Mapped Real Genre': mapped_real_genre,
            'Mapping Label': f"{ai_genre} -> {mapped_real_genre}",
            'Average Cosine Similarity': avg_similarity
        })

# Create DataFrame for analysis
df_results = pd.DataFrame(results_data)

if not df_results.empty:
    plt.figure(figsize=(12, 10))
    sns.set_style("whitegrid")

    sns.stripplot(
        data=df_results,
        x='Average Cosine Similarity',
        y='Mapping Label',
        hue='Mapping Label',
        palette='viridis',
        size=8,
        jitter=True,
        legend=False
    )

    sns.boxplot(
        data=df_results,
        x='Average Cosine Similarity',
        y='Mapping Label',
        color='lightgray',
        fliersize=0, # Hide outliers as they are shown in stripplot
        boxprops=dict(alpha=0.3) # Make boxes transparent
    )

    plt.title(f'Cosine Similarity of Top 10 KNN Matches by Genre Mapping\n(Sample Size: {len(df_results)} AI Songs)', fontsize=15)
    plt.xlabel('Average Cosine Similarity Score', fontsize=12)
    plt.ylabel('Mapping (AI Genre -> Real Genre)', fontsize=12)

    plt.tight_layout()
    plt.show()

    print("Top 5 Samples with Highest Average Similarity:")
    display(df_results.sort_values(by='Average Cosine Similarity', ascending=False).head(5))

else:
    print("No matches found for the selected random samples.")

import matplotlib.pyplot as plt

plt.style.use('seaborn-v0_8-whitegrid')
plt.figure(figsize=(12, 6))
plt.plot(
    df_results.index,
    df_results['Average Cosine Similarity'],
    marker='o',          # Circular markers for each data point
    linestyle='-',       # Solid line connecting points
    linewidth=1.5,
    color='#2c7bb6',     # Professional blue color
    markersize=5,
    alpha=0.8
)

overall_mean = df_results['Average Cosine Similarity'].mean()
plt.axhline(y=overall_mean, color='r', linestyle='--', alpha=0.5, label=f'Mean Similarity (${overall_mean:.3f}$)')

plt.ylim(0.8, 1.0)
plt.title('Average Cosine Similarity of Top 10 KNN Matches per AI Song', fontsize=15, pad=15)
plt.xlabel('AI Song Sample Index', fontsize=12)
plt.ylabel('Average Cosine Similarity', fontsize=12)
plt.legend()
plt.grid(True, linestyle=':', alpha=0.6)
plt.tight_layout()
plt.savefig('ai_song_similarity_trend_v2.png')
plt.show()

"""## Visualizations"""

import matplotlib.pyplot as plt

def topk_sims(index, Q, k=10):
    # Q: (nq, d)
    Q = np.ascontiguousarray(Q.astype(np.float32))
    sims, idxs = index.search(Q, k)
    return sims  # (nq, k)

def plot_similarity_distributions(index, X_real_song, ai_files, embed_path, num_ai=200, k=10, seed=0):
    rng = np.random.default_rng(seed)

    # Real->Real: use each real song as a query; take k=2 and use neighbor #2 to avoid self
    sims_rr, idxs_rr = index.search(X_real_song.astype(np.float32), 2)
    real_to_real = sims_rr[:, 1]  # exclude self match at position 0

    # AI->Real: embed a sample of AI files and query top-1 similarity
    if len(ai_files) == 0:
        raise ValueError("ai_files empty")

    m = min(num_ai, len(ai_files))
    sample_paths = rng.choice(ai_files, size=m, replace=False)

    X_ai = np.stack([embed_path(p) for p in sample_paths], axis=0).astype(np.float32)
    sims_ar = topk_sims(index, X_ai, k=1)[:, 0]  # top-1 similarity

    plt.figure(figsize=(10, 6))
    plt.hist(real_to_real, bins=40, alpha=0.6, label="Real→Real (1-NN, leave-one-out)")
    plt.hist(sims_ar, bins=40, alpha=0.6, label="AI→Real (top-1)")
    plt.xlabel("Cosine similarity (inner product on L2-normalized vectors)")
    plt.ylabel("Count")
    plt.title("Similarity distributions: does AI land near real songs?")
    plt.legend()
    plt.show()

    print("Real→Real (1-NN) mean:", float(real_to_real.mean()), "median:", float(np.median(real_to_real)))
    print("AI→Real (top-1) mean:", float(sims_ar.mean()), "median:", float(np.median(sims_ar)))

# Usage:
plot_similarity_distributions(index, X_real_song, ai_files, embed_path, num_ai=200, k=10)

def same_genre_at_k(index, X_real_song, meta_real, max_k=50):
    labels = meta_real["label"].to_numpy()
    # search max_k+1 so we can drop self
    sims, idxs = index.search(X_real_song.astype(np.float32), max_k + 1)
    idxs = idxs[:, 1:]  # drop self column

    # For each k, compute fraction of neighbors with same label (averaged over queries)
    acc = []
    for k in range(1, max_k + 1):
        neigh_labels = labels[idxs[:, :k]]              # (N, k)
        same = (neigh_labels == labels[:, None])        # (N, k)
        acc.append(same.mean())                         # scalar
    return np.array(acc)

acc = same_genre_at_k(index, X_real_song, meta_real, max_k=50)

plt.figure(figsize=(10, 6))
plt.plot(np.arange(1, 51), acc)
plt.xlabel("k")
plt.ylabel("Fraction of neighbors with same genre")
plt.title("GTZAN retrieval effectiveness: same-genre in top-k")
plt.ylim(0, 1)
plt.show()

print("Same-genre@1:", float(acc[0]))
print("Same-genre@10:", float(acc[9]))
print("Same-genre@50:", float(acc[49]))

import umap
import matplotlib.pyplot as plt

# GTZAN vectors: X_real_song (N, 512), meta_real['label']
reducer = umap.UMAP(n_neighbors=100, min_dist=0.1, random_state=42)
Z_real = reducer.fit_transform(X_real_song)

plt.figure(figsize=(10, 7))
labels = meta_real["label"].astype("category")
plt.scatter(Z_real[:,0], Z_real[:,1], c=labels.cat.codes, s=10)
plt.title("GTZAN OpenL3 embeddings")
plt.show()

# embed a few AI queries and project with the same reducer
m = min(50, len(ai_files))
X_ai = np.stack([embed_path(p) for p in ai_files[:m]], axis=0)
Z_ai = reducer.transform(X_ai)

plt.figure(figsize=(10, 7))
plt.scatter(Z_real[:,0], Z_real[:,1], c=labels.cat.codes, s=10, alpha=0.25)
plt.scatter(Z_ai[:,0], Z_ai[:,1], s=35, marker="x")
plt.title("GTZAN (real) + SONICS (AI queries) in OpenL3 space")
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# 1-NN excluding self: search k=2 and skip the first (self)
scores, idxs = index.search(X_real_song, 2)
nn = idxs[:, 1]

y_true = meta_real["label"].values
y_pred = meta_real["label"].iloc[nn].values

labels_sorted = sorted(meta_real["label"].unique())
cm = confusion_matrix(y_true, y_pred, labels=labels_sorted)

disp = ConfusionMatrixDisplay(cm, display_labels=labels_sorted)
fig, ax = plt.subplots(figsize=(10, 10))
disp.plot(ax=ax, xticks_rotation=90, values_format="d")
plt.title("GTZAN 1-NN retrieval confusion (OpenL3 cosine)")
plt.show()

"""## Top-K Recs for songs predicted as AI using classifier"""

# Classified AI songs path
CLASSIFIED_SONICS = os.path.join(project_path, "test AI generated audio files (SONICs)", "SONICS")

print("AI_DIR =", CLASSIFIED_SONICS)
assert os.path.isdir(CLASSIFIED_SONICS), f"Folder not found: {CLASSIFIED_SONICS}"

# Gather audio paths (recursive)
exts = ("wav", "mp3", "flac", "ogg", "m4a", "aiff", "aif")
ai_paths = []
for e in exts:
    ai_paths += glob.glob(os.path.join(CLASSIFIED_SONICS, "**", f"*.{e}"), recursive=True)

ai_paths = sorted(set(ai_paths))
print("Found", len(ai_paths), "audio files")
for p in ai_paths[:10]:
    print(" -", p)

def infer_ai_genre_from_knn(file_path, k=50):
    """
    Infers genre by weighted average similarity over KNN results.
    """
    knn = knn_query_path(file_path, k=k)  # returns df with columns: label, score
    genre_scores = (
        knn.groupby("label")["score"]
        .mean()
        .sort_values(ascending=False)
    )
    return genre_scores.index[0]

# Build (file_path, inferred_ai_genre)
ai_files_with_genres = []
for p in ai_paths:
    inferred_genre = infer_ai_genre_from_knn(p, k=50)
    ai_files_with_genres.append((p, inferred_genre))
    print(f"{os.path.basename(p)}  →  inferred AI genre: {inferred_genre}")

print("Total AI files:", len(ai_files_with_genres))

results_data = []

print(f"Processing {len(ai_files_with_genres)} AI songs...")

for i, (file_path, ai_genre) in enumerate(ai_files_with_genres):
    print(f"[{i+1}/{len(ai_files_with_genres)}] {os.path.basename(file_path)}")

    # Map inferred AI genre → closest real GTZAN genre
    mapped_real_genre = map_ai_genre_to_closest_real(
        ai_genre_to_map=ai_genre,
        target_real_genres=target_real_genres,
        gtzan_genre_centroids=gtzan_genre_centroids,
        ai_files_with_genres=ai_files_with_genres
    )

    # Query many neighbors, then filter
    knn_results = knn_query_path(file_path, k=200)

    filtered_results = knn_results[
        knn_results["label"] == mapped_real_genre
    ]

    top_10 = (
        filtered_results
        .sort_values(by="score", ascending=False)
        .head(10)
    )

    if not top_10.empty:
        results_data.append({
            "File": os.path.basename(file_path),
            "AI Genre": ai_genre,
            "Mapped Real Genre": mapped_real_genre,
            "Mapping Label": f"{ai_genre} → {mapped_real_genre}",
            "Average Cosine Similarity": float(top_10["score"].mean())
        })

df_results = pd.DataFrame(results_data)
df_results